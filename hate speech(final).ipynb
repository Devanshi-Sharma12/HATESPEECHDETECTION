{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8175fe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn. feature_extraction. text import CountVectorizer\n",
    "from sklearn. model_selection import train_test_split\n",
    "from sklearn. tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "529a7345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "#nltk. download('stopwords')\n",
    "from nltk. corpus import stopwords\n",
    "stopword=set(stopwords.words('english'))\n",
    "stemmer = nltk. SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "729dc408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9801592a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\DELL'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e7fd33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\DELL\\\\OneDrive\\\\Documents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d46b5aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\DELL\\\\OneDrive\\\\Documents'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f087dc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "0           0      3            0                   0        3      2   \n",
      "1           1      3            0                   3        0      1   \n",
      "2           2      3            0                   3        0      1   \n",
      "3           3      3            0                   2        1      1   \n",
      "4           4      6            0                   6        0      1   \n",
      "\n",
      "                                               tweet  \n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n"
     ]
    }
   ],
   "source": [
    "data = pd. read_csv(\"labeled_data.csv\")\n",
    "#To preview the data\n",
    "print(data. head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c223369e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet  \\\n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...   \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
      "\n",
      "                         labels  \n",
      "0  No Hate and Offensive Speech  \n",
      "1              Offensive Speech  \n",
      "2              Offensive Speech  \n",
      "3              Offensive Speech  \n",
      "4              Offensive Speech  \n"
     ]
    }
   ],
   "source": [
    "data[\"labels\"] = data[\"class\"]. map({0: \"Hate Speech\", 1: \"Offensive Speech\", 2: \"No Hate and Offensive Speech\"})\n",
    "data = data[[\"tweet\", \"labels\"]]\n",
    "print(data. head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a6bd1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "653f43fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet  \\\n",
      "0   rt mayasolov woman shouldnt complain clean ho...   \n",
      "1   rt  boy dat coldtyga dwn bad cuffin dat hoe  ...   \n",
      "2   rt urkindofbrand dawg rt  ever fuck bitch sta...   \n",
      "3             rt cganderson vivabas look like tranni   \n",
      "4   rt shenikarobert shit hear might true might f...   \n",
      "\n",
      "                         labels  \n",
      "0  No Hate and Offensive Speech  \n",
      "1              Offensive Speech  \n",
      "2              Offensive Speech  \n",
      "3              Offensive Speech  \n",
      "4              Offensive Speech  \n"
     ]
    }
   ],
   "source": [
    "def clean (text):\n",
    " text = str (text). lower()\n",
    " text = re. sub('\\[.*?\\]', '', text) \n",
    " text = re. sub('https?://\\S+|www\\.\\S+', '', text)\n",
    " text = re. sub('<.*?>+', '', text)\n",
    " text = re. sub('[%s]' % re. escape(string. punctuation), '', text)\n",
    " text = re. sub('\\n', '', text)\n",
    " text = re. sub('\\w*\\d\\w*', '', text)\n",
    " text = [word for word in text.split(' ') if word not in stopword]\n",
    " text=\" \". join(text)\n",
    " text = [stemmer. stem(word) for word in text. split(' ')]\n",
    " text=\" \". join(text)\n",
    " return text\n",
    "data[\"tweet\"] = data[\"tweet\"]. apply(clean)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "190fb63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np. array(data[\"tweet\"])\n",
    "y = np. array(data[\"labels\"])\n",
    "cv = CountVectorizer()\n",
    "X = cv. fit_transform(x)\n",
    "# Splitting the Data\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6a6434b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model building\n",
    "model = DecisionTreeClassifier()\n",
    "#Training the model\n",
    "model. fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f666a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Offensive Speech', 'Offensive Speech', 'Offensive Speech', ...,\n",
       "       'Offensive Speech', 'Offensive Speech', 'Offensive Speech'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing the model\n",
    "y_pred = model. predict (X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c877fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87614622814525\n"
     ]
    }
   ],
   "source": [
    "#Accuracy Score of our model\n",
    "from sklearn. metrics import accuracy_score\n",
    "print (accuracy_score (y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28865348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Offensive Speech']\n"
     ]
    }
   ],
   "source": [
    "#Predicting the outcome\n",
    "inp = \"You are too bad and I dont like your attitude\"\n",
    "inp = cv.transform([inp]).toarray()\n",
    "print(model.predict(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e024048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No Hate and Offensive Speech']\n"
     ]
    }
   ],
   "source": [
    "inp = \"It is really awesome\"\n",
    "inp = cv. transform([inp]). toarray()\n",
    "print(model. predict(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d12eab7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
