{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRvkdwKt6tgwUHkDMTCIyW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Devanshi-Sharma12/HATESPEECHDETECTION/blob/main/mainfile.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwA6QPrq_QdA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn. feature_extraction. text import CountVectorizer\n",
        "from sklearn. model_selection import train_test_split\n",
        "from sklearn. tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1sOKqko_3YQ",
        "outputId": "4781506f-d3cc-4e63-eaf0-8fc77cdd737e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "\n",
        "# Uncomment the line below to download stopwords if not already downloaded\n",
        "# nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stopword = set(stopwords.words('english'))\n",
        "stemmer = nltk.SnowballStemmer(\"english\")\n",
        "\n",
        "# Now you can proceed with using the stopwords and stemmer objects in your script\n"
      ],
      "metadata": {
        "id": "0cXndiHu_5Du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "9shBJ0_F_-c7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "LojUw7BhAEWl",
        "outputId": "6d21668a-61b1-438d-f570-e4688ce7baa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the path to the Documents folder in Google Drive\n",
        "drive_path = '/content/drive/My Drive'\n",
        "documents_path = os.path.join(drive_path, 'Documents')\n",
        "\n",
        "# Check if the Documents folder exists and create it if necessary\n",
        "if not os.path.exists(documents_path):\n",
        "    os.makedirs(documents_path)\n",
        "    print(f\"Created '{documents_path}' directory.\")\n",
        "\n",
        "# Change the working directory to the Documents folder\n",
        "os.chdir(documents_path)\n",
        "print(f\"Changed directory to '{documents_path}' successfully.\")\n",
        "print(f\"Current working directory: {os.getcwd()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_zfekcYL61L",
        "outputId": "b15dc089-103a-45fe-94cf-b0179d1db6e1"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Changed directory to '/content/drive/My Drive/Documents' successfully.\n",
            "Current working directory: /content/drive/My Drive/Documents\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Q7du4d6_L_uw",
        "outputId": "3c863e2c-af49-40c4-ad80-d20e79ba1e5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/Documents'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd. read_csv(\"labeled_data.csv\")\n",
        "#To preview the data\n",
        "print(data. head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWRY6KjZMDgx",
        "outputId": "488885b5-b4f9-4428-cb89-50fd87acaf39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
            "0           0      3            0                   0        3      2   \n",
            "1           1      3            0                   3        0      1   \n",
            "2           2      3            0                   3        0      1   \n",
            "3           3      3            0                   2        1      1   \n",
            "4           4      6            0                   6        0      1   \n",
            "\n",
            "                                               tweet  \n",
            "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
            "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
            "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
            "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
            "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"labels\"] = data[\"class\"]. map({0: \"Hate Speech\", 1: \"Offensive Speech\", 2: \"No Hate and Offensive Speech\"})\n",
        "data = data[[\"tweet\", \"labels\"]]\n",
        "print(data. head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftRdpTbYPVid",
        "outputId": "9117d55d-8353-4de4-93af-e8576d793546"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               tweet  \\\n",
            "0  !!! RT @mayasolovely: As a woman you shouldn't...   \n",
            "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
            "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
            "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
            "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
            "\n",
            "                         labels  \n",
            "0  No Hate and Offensive Speech  \n",
            "1              Offensive Speech  \n",
            "2              Offensive Speech  \n",
            "3              Offensive Speech  \n",
            "4              Offensive Speech  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string"
      ],
      "metadata": {
        "id": "glNO-KJEPaXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean (text):\n",
        " text = str (text). lower()\n",
        " text = re. sub('\\[.*?\\]', '', text)\n",
        " text = re. sub('https?://\\S+|www\\.\\S+', '', text)\n",
        " text = re. sub('<.*?>+', '', text)\n",
        " text = re. sub('[%s]' % re. escape(string. punctuation), '', text)\n",
        " text = re. sub('\\n', '', text)\n",
        " text = re. sub('\\w*\\d\\w*', '', text)\n",
        " text = [word for word in text.split(' ') if word not in stopword]\n",
        " text=\" \". join(text)\n",
        " text = [stemmer. stem(word) for word in text. split(' ')]\n",
        " text=\" \". join(text)\n",
        " return text\n",
        "data[\"tweet\"] = data[\"tweet\"]. apply(clean)\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61S_eWxJPecO",
        "outputId": "6141e5e2-4536-4bbc-9d8a-2bece268534e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               tweet  \\\n",
            "0   rt mayasolov woman shouldnt complain clean ho...   \n",
            "1   rt  boy dat coldtyga dwn bad cuffin dat hoe  ...   \n",
            "2   rt urkindofbrand dawg rt  ever fuck bitch sta...   \n",
            "3             rt cganderson vivabas look like tranni   \n",
            "4   rt shenikarobert shit hear might true might f...   \n",
            "\n",
            "                         labels  \n",
            "0  No Hate and Offensive Speech  \n",
            "1              Offensive Speech  \n",
            "2              Offensive Speech  \n",
            "3              Offensive Speech  \n",
            "4              Offensive Speech  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np. array(data[\"tweet\"])\n",
        "y = np. array(data[\"labels\"])\n",
        "cv = CountVectorizer()\n",
        "X = cv. fit_transform(x)\n",
        "# Splitting the Data\n",
        "X_train, X_test, y_train, y_test =train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "JnOSpFD6Php9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model building\n",
        "model = DecisionTreeClassifier()\n",
        "#Training the model\n",
        "model. fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "woMsAwxEPlK6",
        "outputId": "75bf7204-61c9-4b9a-b557-f9dfbf1012ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing the model\n",
        "y_pred = model. predict (X_test)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8HXE0DDPp3T",
        "outputId": "c853df4c-f84b-455d-a767-5c5047359247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Offensive Speech', 'Offensive Speech', 'Offensive Speech', ...,\n",
              "       'Offensive Speech', 'Offensive Speech', 'Offensive Speech'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Accuracy Score of our model\n",
        "from sklearn. metrics import accuracy_score\n",
        "print (accuracy_score (y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeZnFt4CSIyn",
        "outputId": "ae58e2f9-7a12-4f4c-b49b-177e8e7e4f04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.87687981415821\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicting the outcome\n",
        "inp = \"You are too bad and I dont like your attitude\"\n",
        "inp = cv.transform([inp]).toarray()\n",
        "print(model.predict(inp))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_03fSI4SRba",
        "outputId": "e977db12-b5ce-4215-ad78-62365783db52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Offensive Speech']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp = \"It is really awesome\"\n",
        "inp = cv. transform([inp]). toarray()\n",
        "print(model. predict(inp))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCR2fiusSZKT",
        "outputId": "e0898ff6-5c7f-42e4-93d0-8b84e33bb4bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['No Hate and Offensive Speech']\n"
          ]
        }
      ]
    }
  ]
}